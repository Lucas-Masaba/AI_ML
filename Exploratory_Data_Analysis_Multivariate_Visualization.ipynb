{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucas-Masaba/AI_ML/blob/main/Exploratory_Data_Analysis_Multivariate_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate Analysis\n",
        "\n",
        "Univariate visualizations are great for understanding one column, but, by definition, they cannot tell us about the relationships between columns. Therefore, we need additional types of visualizations that explore the relationships between 2 or more columns.\n",
        "\n",
        "In Data Science, we identify one of the columns as the values we want to explain or predict. We call these types of columns the \"target.\" The remaining columns are considered our \"features.\"\n",
        "\n",
        "As with univariate visualizations, the type of visualization we select will be based on the data types we want to visualize.\n",
        "\n",
        "However, now we have two columns to consider:\n",
        "\n",
        "* the target's data type (numeric vs. categorical)\n",
        "* the feature's data type (numeric vs. categorical)  \n",
        "\n",
        "A few examples of multivariate plots you will learn to make are:"
      ],
      "metadata": {
        "id": "yXhueTxHRUYr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Boxplots**\n",
        "\n",
        "<img src=\"https://assets.codingdojo.com/boomyeah2015/codingdojo/curriculum/content/chapter/1682105968__1681850473.png\">  \n",
        "\n",
        "**A Heatmap of Correlation Values**  \n",
        "\n",
        "<img src=\"https://assets.codingdojo.com/boomyeah2015/codingdojo/curriculum/content/chapter/1682106077__1681852763.png\">  \n",
        "\n",
        "**Regression Plots**\n",
        "\n",
        "<img src=\"https://assets.codingdojo.com/boomyeah2015/codingdojo/curriculum/content/chapter/1682106147__1682015966Capture.png\" width=\"50%\">\n",
        "\n",
        "**Boxen Plot**  \n",
        "\n",
        "<img src=\"https://assets.codingdojo.com/boomyeah2015/codingdojo/curriculum/content/chapter/1682106214__1682029282Capture.png\"  width=\"50%\">\n"
      ],
      "metadata": {
        "id": "Qoo3LostRhDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bar Plots\n",
        "\n",
        "We shall use data from [here](https://drive.google.com/file/d/1UnL59IupYrZd6f3oxkZxttYiNTxDVNMR/view?usp=drive_link) for this section."
      ],
      "metadata": {
        "id": "XteuPJsAW5V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "86SQqycTUrP_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "MR_n6Y3rRgkO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "filename = \"/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/ames-housing-cleaned-eda.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sEipJ-2gXUii",
        "outputId": "6eabfed2-4dc9-4f17-da4b-26969b63bce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a2b8259aa72b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/ames-housing-cleaned-eda.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/ames-housing-cleaned-eda.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the Bldg Type column\n",
        "df['Bldg Type'].value_counts()"
      ],
      "metadata": {
        "id": "4NW_Vt_ZXb99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the [data dictionary](https://docs.google.com/document/d/1nmnel7g35aMOl0mKiSsTHXT8wRzbJ1EktKNqYFEmpWE/edit?usp=sharing) for the meaning of the category names.\n",
        "\n",
        "- For \"Bldg Type\"\n",
        "  * 1Fam: Single-family Detached\n",
        "  * 2FmCon: Two-family Conversion; originally built as a one-family dwelling\n",
        "  * Duplx: Duplex\n",
        "  * TwnhsE: Townhouse End Unit\n",
        "  * TwnhsI: Townhouse Inside Unit"
      ],
      "metadata": {
        "id": "w_V4wrH2XoCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use groupby to calculate the average for each category\n",
        "bldg_type_prices = df.groupby('Bldg Type')['SalePrice'].mean()\n",
        "bldg_type_prices"
      ],
      "metadata": {
        "id": "8NYG1qm-X4AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the average of each as a bar\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(bldg_type_prices.index, bldg_type_prices.values);\n",
        "ax.set_ylabel('SalePrice')\n",
        "ax.set_xlabel(\"Bldg Type\");"
      ],
      "metadata": {
        "id": "dQ1j874xYBRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using pandas to plot the means\n",
        "ax = bldg_type_prices.plot(kind='bar')\n",
        "ax.set_ylabel(\"Sale Price\");"
      ],
      "metadata": {
        "id": "KmGi6920YND7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using seaborn to plot the group means\n",
        "ax = sns.barplot(data=df, x='Bldg Type', y=\"SalePrice\")"
      ],
      "metadata": {
        "id": "5sT_n_JzYXUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouped bar charts\n",
        "# Using seaborn to plot the group means by Buildign Type colored by Central Air\n",
        "ax = sns.barplot(data=df, x=\"Bldg Type\", y=\"SalePrice\", hue='Central Air')"
      ],
      "metadata": {
        "id": "VmmGvr_cYqTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"Bldg Type\", \"Central Air\"]]"
      ],
      "metadata": {
        "id": "NgkTr0X9ZGlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that our BldgTypes are still on the x-axis, but each building type no longer has a different color.\n",
        "\n",
        "Instead, Blue was used to represent homes with Central Air (\"Y\"), and Orange was used to represent homes without Central Air (\"N\").\n",
        "\n",
        "Note that this graph would be VERY hard to reproduce with matplotlib. It is possible, but it would take many more lines of code, and the final result would not be as aesthetically pleasing.\n",
        "\n",
        "Before we added Central Air as the hue, we saw that \"1Fam\" and \"TwnhsE\" had the highest average Sale Prices.\n",
        "\n",
        "Now that we have added Central Air, we can see that this was a little misleading.\n",
        "\n",
        "TwnheE and Single Family with Central Air have the highest Sale Price. If we look at the 1Fam homes without Central Air, we can see that these homes have the lowest Sale Price.\n",
        "\n",
        "Note that you may want to test out swapping which column to use as x and which to use as hue, depending on which column we want to compare across groups.\n",
        "\n",
        "Let's swap our x and hue so that our binary category of Bldg Type is the hue."
      ],
      "metadata": {
        "id": "yTqfhqSFZnKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using seaborn to plot the group means by central air colored by Bldg Type\n",
        "ax = sns.barplot(data=df, x=\"Central Air\", y=\"SalePrice\", hue='Bldg Type')"
      ],
      "metadata": {
        "id": "UFWQmapFZoY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation and Heat Maps\n",
        "**What is correlation?**  \n",
        "\n",
        "As data scientists, we are often interested in if (and how) different features of a dataset may be related.  For numerical data, one key way to describe a relationship is the correlation between the values.  \n",
        "There are different types of correlation:\n"
      ],
      "metadata": {
        "id": "AYPiYmN2e6gL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Correlation  \n",
        "If two variables change in the same direction, they have a positive correlation.  For example, there is a positive correlation between hours worked and paycheck (if you are paid by the hour!).  As hours goes up, paycheck goes up.  As hours go down, paycheck goes down.\n",
        "\n"
      ],
      "metadata": {
        "id": "sHAzjl42PSgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative Correlation  \n",
        "If two variable change in the opposite direction, they have a negative correlation.  For example, there is a negative correlation between altitude and temperature.  As altitude goes up, temperature goes down.  As altitude goes down, temperature goes up.  "
      ],
      "metadata": {
        "id": "tQaYWcBeQJme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Correlation  \n",
        "There is no relationship between a person's height and the cost of bread! So these variables are not correlated.  \n",
        "\n",
        "We can also calculate the level of correlation between variables. Some of the popular methods used to calculate the degree of correlation in statistics are [Kendall's Correlation Coefficient](https://https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), [Spearman's Correlation Coefficient](https://https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) and [Pearson's Coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).    \n",
        "  \n",
        "   \n",
        "The correlation coefficient (**r**) ranges from -1 to +1.\n",
        "Specifically, for **negative correlation** value lies between 0 up to -1 with higher magnitude meaning a higher correlation ie. -5 is a higher correlation than -3.\n",
        "  \n",
        "**Positive correlation** value ranges from 0 to +1 with higher values implying a stronger correlation."
      ],
      "metadata": {
        "id": "w4GdI5XBQOhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation is NOT causation!**  \n",
        "It can be tempting to misinterpret a correlation as one variable causing the values of another to change. We cannot conclude anything about the cause of a change based on correlation. All we can conclude is that there is a relationship between the variables."
      ],
      "metadata": {
        "id": "LRMtjicTaILU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting correlation between variables with Pandas.\n",
        "In pandas we can get the correlation between different variables/columns using the dataframe .corr() method. By default, the .corr() method computes the correlaton using the Pearson's method, but supports the above mentioned methods or even a custom function. ([see documentation of .corr() method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QULWMB50tVvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are first going to demo this with a smaller dataset that has information about Olympic medalists. This is a [direct URL](https://docs.google.com/spreadsheets/d/e/2PACX-1vTtqWeFFAV3GA13M4eXdzMkAKAxIQ7fek4kv16wntAI_2QfYzm_BxdW6HVblVHy0VFRwsA47xFn8--6/pub?output=csv) for this dataset."
      ],
      "metadata": {
        "id": "p-I1v7VGaofP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us load our data\n",
        "filename = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTtqWeFFAV3GA13M4eXdzMkAKAxIQ7fek4kv16wntAI_2QfYzm_BxdW6HVblVHy0VFRwsA47xFn8--6/pub?output=csv\"\n",
        "df = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "75TXMghBVCbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the data\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "JXTahE8dVO2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many columns do we have?"
      ],
      "metadata": {
        "id": "pp11AMYnVS25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What are the datatypes of each column?"
      ],
      "metadata": {
        "id": "UX1LAxR3VXdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times does each team appear in the column Team?"
      ],
      "metadata": {
        "id": "P2p6OVOfVhTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do we have any null values?"
      ],
      "metadata": {
        "id": "nCGyolP4VomD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the correlation between columns"
      ],
      "metadata": {
        "id": "iW60eKHiV3h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "dFS2WANHtAPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the dataframe .corr() method.\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "z7r7-QQGVs-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To suppress the warning, consider only numeric columns pb passing True for the numeric_only parameter\n",
        "df.corr(numeric_only = True)"
      ],
      "metadata": {
        "id": "MbOmHx6ObeNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can check the type\n",
        "type(df.corr())"
      ],
      "metadata": {
        "id": "0AN6z13-WQXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it in a variable\n",
        "correlation_df = df.corr(numeric_only = True)"
      ],
      "metadata": {
        "id": "AhJoDEGaWUNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_df.head()"
      ],
      "metadata": {
        "id": "7ouCHicxWYJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The .corr() method compres each column against the others and computes the correlation coefficient.  \n",
        "How can we complement this information?  \n",
        "Answer: **Visualization**"
      ],
      "metadata": {
        "id": "f927LwAuWfQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the visualize the correlation_df using the heatmap plot in Seaborn. The heatmap shows a visual representation of the correlation values and the magnitude of correlation.  \n",
        "To do this, we simply pass the correlation_df to the method and can add some additional parameters to beutify our plot"
      ],
      "metadata": {
        "id": "v-Ub-p1lW7Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using seaborn heatmap to visualize the correlation dataframe\n",
        "sns.heatmap(correlation_df)"
      ],
      "metadata": {
        "id": "Svda32H1WdyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looks beautiful but its a bit difficult to interprete.\n",
        "# let's add a few parameters like cmap. cmap defines the\n",
        "# color we want to use for our heatmap e.g Blues, Greens,..\n",
        "sns.heatmap(correlation_df, cmap = 'Blues')"
      ],
      "metadata": {
        "id": "Zq-QPqBgX0Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This definetly looks better with one color. The darker shades of blue imply a higher correlation coeficient and the vice-versa is true.  \n",
        "But we can do even one better."
      ],
      "metadata": {
        "id": "ONcZooS4YPps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By passing the parameter True for the annot argument\n",
        "sns.heatmap(correlation_df, cmap = 'Blues', annot=True)"
      ],
      "metadata": {
        "id": "BDJ4T26aYp0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: The correlation coefficient between the same variable is always 1\n",
        "\n",
        "\n",
        "In general a correlation coefficient greater than 0.7 is considered \"strong.\"\n",
        "\n",
        "Between 0.5 and 0.7 is considered \"moderate\".  \n",
        "\n",
        "Between 0.3 and 0.5 is considered  a \"low\" correlation.\n",
        "\n",
        "\n",
        "However, these rules of thumb can vary between content areas!"
      ],
      "metadata": {
        "id": "RrOlG5KqZnKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the Ames Dataset\n",
        "\n",
        "You can get the data from [here](https://drive.google.com/file/d/1UnL59IupYrZd6f3oxkZxttYiNTxDVNMR/view?usp=drive_link)"
      ],
      "metadata": {
        "id": "4T35ts4xcwwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "filename = \"/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/ames-housing-cleaned-eda.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Tp3A4xsCdEE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get correlations\n",
        "# Get correlations\n",
        "corr = df.corr(numeric_only = True)\n",
        "corr.round(2)"
      ],
      "metadata": {
        "id": "4sdfJgHXdJYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make heatmap to visualize correlations\n",
        "sns.heatmap(corr, cmap = 'coolwarm', annot = True);"
      ],
      "metadata": {
        "id": "uwi2WPUOdSqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the plot with matplotlib e.g. increaze the size using the figsize parameter\n",
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "sns.heatmap(corr, cmap = 'Greens', annot = True, ax=ax);"
      ],
      "metadata": {
        "id": "nxoUmb4ydWlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression Plots  \n",
        "\n",
        "**Plotting numeric features vs numeric target**  \n",
        "\n",
        "As we visualize the relationships between our features and the target, we need a type of chart that will allow us to plot numeric X columns vs. a numeric y. You've already seen a very simple plot for plotting 2 numeric features: the scatter plot."
      ],
      "metadata": {
        "id": "p6uOIUqyeQkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can make a scatter plot with pandas' .plot. and pass scatter argrument for the kind parameter.\n",
        "ax = df.plot(kind='scatter', x='Living Area Sqft', y='SalePrice');"
      ],
      "metadata": {
        "id": "mH2wNt1DekAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plot with Matplotlib\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(df['Living Area Sqft'], df['SalePrice']);\n",
        "ax.set(xlabel='Living Area Sqft', ylabel=\"SalePrice\");"
      ],
      "metadata": {
        "id": "8pu0E1X4exUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot with Seaborn\n",
        "sns.scatterplot(data=df, x='Living Area Sqft', y='SalePrice')"
      ],
      "metadata": {
        "id": "P501FZ4qe_2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a scatterplot using Central Air as the hue argument\n",
        "ax = sns.scatterplot(data=df, x=\"Living Area Sqft\" , y=\"SalePrice\",\n",
        "                     hue=\"Central Air\");"
      ],
      "metadata": {
        "id": "GN_N8oJjg_Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the Trend between X and y\n",
        "We can see the Living Area Sqft on the X-axis and the Sale Price on the Y-axis. It looks like as we increase the value of X (move right along the x-axis), the value for Y seems to increase. There are several markers that don't follow this trend perfectly.\n",
        "\n",
        "We want to visually summarize the overall relationship between the x and y. The easiest way to do so is to use Seaborn's sns.regplot function.\n",
        "\n",
        "The regplot is very helpful, as it will:\n",
        "\n",
        "1. Create a scatter plot with Matplotlib\n",
        "2. Calculate a line of best fit using another package (either statsmodels or SciPy, depending),.\n",
        "3. Finally, it will plot the trend line using Matplotlib."
      ],
      "metadata": {
        "id": "WMm6fmzMfV61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.regplot requires the same arguments as scatterplot\n",
        "ax = sns.regplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\");"
      ],
      "metadata": {
        "id": "AWzADjRkfs7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customization\n",
        "# there is a number of things that can be customized on the seaborn regplot like the line, markers,...\n",
        "\n",
        "# Saving the arguments for the line color in a dict to to use as line_kws\n",
        "line_kws = dict(color='black')\n",
        "ax = sns.regplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\",\n",
        "                 line_kws=line_kws)"
      ],
      "metadata": {
        "id": "nLE--QVrgezB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the arguments for the markers' edge color in a dict to to use as scatter_kws\n",
        "scatter_kws = dict(edgecolor='white')\n",
        "ax = sns.regplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\",\n",
        "                 line_kws=line_kws, scatter_kws=scatter_kws);"
      ],
      "metadata": {
        "id": "zQOI-HzzgtlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hue argument works so easily with sns.scatterplot, we would expect the regplot to also accept a hue argument, but it does not!\n",
        "\n",
        "Instead, there is a more advanced plot that will allow us to display trendlines for groups.\n",
        "\n",
        "The More Advanced Regression Plot: the Linear Model Plot\n",
        "\n",
        "There is a second class of Seaborn plots that are more complex than the normal Matplotlib plots that we have used so far. So far, we have only used Seaborn plots that return a simple Matplotlib Axes. The more advanced type of Seaborn plots returns a special Seaborn object called a FacetGrid, instead of a Matpotlib Axes.\n",
        "\n",
        "We shall use the [sns.lmplot](https://seaborn.pydata.org/generated/seaborn.lmplot.html)"
      ],
      "metadata": {
        "id": "IQBaonU8hOEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use sns.lmplot and save as g\n",
        "g = sns.lmplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\",\n",
        "                hue=\"Central Air\");"
      ],
      "metadata": {
        "id": "405av1m1hPa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding back the scatter_kws\n",
        "g= sns.lmplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\",\n",
        "               scatter_kws=scatter_kws,\n",
        "                hue=\"Central Air\");"
      ],
      "metadata": {
        "id": "wjNbRuy7honE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take note that the returned object is a seaborn FacetGrid object and not the matplotlib Axes object\n",
        "type(g)"
      ],
      "metadata": {
        "id": "vQH0GLLYhqvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib Axes object is wrapped under the returned seaborn object and can be accessed with the dot notation to enable the use of matplotlib methods\n",
        "\n",
        "# Set the title using g.ax.set_title()\n",
        "g = sns.lmplot(data=df, x=\"Living Area Sqft\", y=\"SalePrice\",\n",
        "               scatter_kws=scatter_kws,\n",
        "                hue=\"Central Air\");\n",
        "g.ax.set_title(\"LM Plot\");"
      ],
      "metadata": {
        "id": "TWzxUrjhhzcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate Categorical Plots\n",
        "**When to Use?**\n",
        "Multivariate categorical plots should be used when you are comparing:\n",
        "- Categorical Features (X) vs. a Numeric Target (y)\n",
        "- Categorical Features (X) vs. a Categorical Target (y)"
      ],
      "metadata": {
        "id": "FSO2_2TViXPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how many categories in each categorical column\n",
        "df.select_dtypes('object').nunique()"
      ],
      "metadata": {
        "id": "qboZTlD7ibzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Plots**"
      ],
      "metadata": {
        "id": "M1HHDXFVjFCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember the Univariate countplot\n",
        "ax = sns.countplot(data=df, x='Bldg Type')"
      ],
      "metadata": {
        "id": "X8DPt-k5il5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multivariate countplot with a hue argument\n",
        "ax = sns.countplot(data=df, x='Bldg Type', hue='Central Air')"
      ],
      "metadata": {
        "id": "Z1vbW27Gi5Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bar plots**"
      ],
      "metadata": {
        "id": "T8me_tV0jJxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a seaborn barplot as a starting point\n",
        "ax = sns.barplot(data=df, x='Bldg Type', y='Living Area Sqft')"
      ],
      "metadata": {
        "id": "LQ_yDjPhjONp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the striplot which is a categorical scatter plot to view more information about each category.\n",
        "# Stripplot takes the same arguments as barplot\n",
        "ax = sns.stripplot(data=df, x='Bldg Type', y='Living Area Sqft',\n",
        "                   hue='Bldg Type')"
      ],
      "metadata": {
        "id": "wBKsYHCcjdHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customizing the stipplot\n",
        "ax = sns.stripplot(data=df, x='Bldg Type', y='Living Area Sqft',\n",
        "                   hue='Bldg Type', edgecolor='white', linewidth=1)\n"
      ],
      "metadata": {
        "id": "sRuO6P5AjoVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seaborn hasd a powerful catplot method which enabels us to specify different types plots using the kind argument. The options for kind are:\n",
        "\n",
        "- \"strip\" (default)\n",
        "- \"swarm\"\n",
        "- \"bar\"\n",
        "- \"count\"\n",
        "- \"box\"\n",
        "- \"boxen\"\n",
        "- \"violin\""
      ],
      "metadata": {
        "id": "Idtwu5T_j4P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using catplot to make a swarmplot, include size argument s=1\n",
        "g = sns.catplot(data=df, x='Bldg Type', y='Living Area Sqft',hue='Bldg Type',\n",
        "                kind='swarm', s=1)"
      ],
      "metadata": {
        "id": "KhgiTIV-kJSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using catplot to make a boxplot, adding dodge=False to reduce white space\n",
        "g = sns.catplot(data=df, x='Bldg Type', y='Living Area Sqft',hue='Bldg Type',\n",
        "                kind='box', dodge=False)"
      ],
      "metadata": {
        "id": "3M_NYaUklH1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using catplot to make a violin plot\n",
        "g = sns.catplot(data=df, x='Bldg Type', y='Living Area Sqft',hue='Bldg Type',\n",
        "                kind='violin', dodge=False)"
      ],
      "metadata": {
        "id": "QUqb-ARElRFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using catplot to make a violin plot\n",
        "g = sns.catplot(data=df, x='Bldg Type', y='Living Area Sqft',hue='Bldg Type',\n",
        "                kind='boxen', dodge = False)"
      ],
      "metadata": {
        "id": "zJ7WKiyNlW94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subplots\n",
        "Many times we may want to compare our data side-by-side using visualizations. We can do this with subplots. Let us use this [dataset](https://drive.google.com/file/d/1Z6RnlnzKyiT-byN6x6XcUYt62s_13Lgg/view?usp=sharing) to illustrate this."
      ],
      "metadata": {
        "id": "nZ27tNEtiHW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and view the top rows in our dataframe\n",
        "filename = \"/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/linearRegPredicted.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3BJDloaMmG7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to compare 2 scatter and line plots side by side."
      ],
      "metadata": {
        "id": "zBAtRamlmXLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create filter for our data with intercept\n",
        "interceptFilter = df['intercept'] == True\n",
        "\n",
        "# Filter the data\n",
        "df_intercept = df.loc[interceptFilter, :]\n",
        "df_nointercept = df.loc[~interceptFilter, :] # Note te use of the ~ operator."
      ],
      "metadata": {
        "id": "YlLjNREpmhNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall use the subplot() method which takes 3 parameters i.e  \n",
        " **matplotlib.subplot(rows, columns, position)**"
      ],
      "metadata": {
        "id": "-IUoCw6vnGPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matlab-style\n",
        "\n",
        "\n",
        "# Play with this code and see what happens!\n",
        "# Adjust size of figure\n",
        "plt.figure(figsize=(8,4))\n",
        "# Subplot 1\n",
        "plt.subplot(1, 2, 1);\n",
        "plt.plot(df_intercept['feature'].values, df_intercept['predicted'].values, c = 'r');\n",
        "plt.scatter(df_intercept['feature'].values, df_intercept['actual'].values, c= 'k');\n",
        "plt.title('intercept', fontsize = 12);\n",
        "# Subplot 2\n",
        "plt.subplot(1, 2, 2);\n",
        "plt.plot(df_nointercept['feature'].values, df_nointercept['predicted'].values, c = 'r');\n",
        "plt.scatter(df_nointercept['feature'].values, df_nointercept['actual'].values, c= 'k');\n",
        "plt.title('no intercept', fontsize = 12);"
      ],
      "metadata": {
        "id": "Q9-w7hF3m1PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a legend to your plots"
      ],
      "metadata": {
        "id": "JjPK4Q-Mn3yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object-oriented\n",
        "\n",
        "# Play with this code and see what happens!\n",
        "# Adjust size of figure and create subplots\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize=(8,4));\n",
        "# Subplot 1\n",
        "axes[0].plot(df_intercept['feature'].values, df_intercept['predicted'].values, c = 'r');\n",
        "axes[0].scatter(df_intercept['feature'].values, df_intercept['actual'].values, c= 'k');\n",
        "axes[0].set_title('intercept', fontsize = 12);\n",
        "# Subplot 2\n",
        "axes[1].plot(df_nointercept['feature'].values, df_nointercept['predicted'].values, c = 'r');\n",
        "axes[1].scatter(df_nointercept['feature'].values, df_nointercept['actual'].values, c= 'k');\n",
        "axes[1].set_title('no intercept', fontsize = 12);"
      ],
      "metadata": {
        "id": "NVi9GijBoA3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your task\n",
        "Recreate the plots above using the seaborn regplot/lmplot"
      ],
      "metadata": {
        "id": "x3Mawhx8m-Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving plots\n",
        "Sometimes you may wan to save your plots as files(pictures) that you may want to use externally or for reference e.g. in a report.\n",
        "Pick data from [here](https://drive.google.com/file/d/1MFl7V1Hs0-jxbq5d5WwaW-d8cSDMYWia/view?usp=sharing)."
      ],
      "metadata": {
        "id": "kx1Kzoz3aY9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data and view top\n",
        "filename = \"/content/drive/MyDrive/AI_ML_Data_Analytics/slides/Week 3/linearRegPredicted.csv\"\n",
        "df = pd.read_csv(filename)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "Fp6ZeaFq1jTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's extract the series and store them in variables.\n",
        "feature = df['feature'].values\n",
        "actual = df['actual'].values\n",
        "predicted = df['predicted'].values"
      ],
      "metadata": {
        "id": "ttsoEw_Rbva0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can save the plots using the savefig() method of matplotlib as shown below."
      ],
      "metadata": {
        "id": "ttEPVfPqcV-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MATLAB-style\n",
        "plt.plot(feature, predicted, c = 'r', label = 'Prediction')\n",
        "plt.scatter(feature, actual, c= 'k', label = 'Actual')\n",
        "plt.legend(loc=(1.02,0))\n",
        "plt.savefig('legendcutoff.png', dpi = 300)"
      ],
      "metadata": {
        "id": "MOFxPvxEcDGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the saved image we can see that the legend has been cut off. We can use the tight_layout() method to sove this."
      ],
      "metadata": {
        "id": "8Ub03NbEdizi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(feature, predicted, c = 'r', label = 'Prediction')\n",
        "plt.scatter(feature, actual, c= 'k', label = 'Actual')\n",
        "plt.legend(loc=(1.02,0))\n",
        "plt.tight_layout() # This solves our problem\n",
        "plt.savefig('legendnotcutoff.png', dpi = 300)"
      ],
      "metadata": {
        "id": "T2MO_ZSOczwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save image properly\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 1);\n",
        "axes.plot(feature, predicted, c = 'r', label = 'Prediction')\n",
        "axes.scatter(feature, actual, c= 'k', label = 'Actual')\n",
        "axes.legend(loc=(1.02,0))\n",
        "fig.tight_layout()\n",
        "plt.savefig('obj_legendnotcutoff.png', dpi = 300)"
      ],
      "metadata": {
        "id": "YuJxY5iqhC3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object-oriented\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 1);\n",
        "axes.plot(feature, predicted, c = 'r', label = 'Prediction')\n",
        "axes.scatter(feature, actual, c= 'k', label = 'Actual')\n",
        "axes.legend(loc=(1.02,0))\n",
        "plt.savefig('obj_legendcutoff.png', dpi = 300)"
      ],
      "metadata": {
        "id": "jOx4HbscehI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading: Multiple Subblots"
      ],
      "metadata": {
        "id": "ioH_jAXoDNPO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zz_bIuslDLKV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}